{
 "cells": [
  {
   "cell_type": "raw",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7450bbba7b5d038b"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-04T22:38:33.311215Z",
     "start_time": "2024-02-04T22:38:32.950208Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def feat_sel_sim(data, measure='luca', p=1):\n",
    "    # Extracting dimensions\n",
    "    l = np.max(data[:, -1])  # Number of classes\n",
    "    m = data.shape[0]        # Number of samples\n",
    "    t = data.shape[1] - 1    # Number of features\n",
    "    \n",
    "    dataold = data.copy()\n",
    "    tmp = []\n",
    "    \n",
    "    # Forming idealvec using arithmetic mean\n",
    "    idealvec_s = np.zeros((l, t))\n",
    "    for k in range(1, int(l) + 1):\n",
    "        idealvec_s[k - 1, :] = np.mean(data[data[:, -1] == k, :t], axis=0)\n",
    "\n",
    "    # Scaling data between [0, 1]\n",
    "    data_v = data[:, :t]\n",
    "    data_c = data[:, t]  # Labels\n",
    "    mins_v = np.min(data_v, axis=0)\n",
    "    data_v = data_v + np.tile(np.abs(mins_v), (m, 1))\n",
    "    tmp = np.tile(np.abs(mins_v), (l, 1))\n",
    "    idealvec_s = idealvec_s + tmp\n",
    "    maxs_v = np.max(data_v, axis=0)\n",
    "    data_v = data_v / maxs_v\n",
    "    idealvec_s = idealvec_s / np.tile(maxs_v, (l, 1))\n",
    "    data = np.column_stack((data_v, data_c))\n",
    "    \n",
    "    # Sample data\n",
    "    datalearn_s = data[:, :t]\n",
    "\n",
    "    # Similarities\n",
    "    sim = np.zeros((t, m, int(l)))\n",
    "    for j in range(m):\n",
    "        for i in range(t):\n",
    "            for k in range(int(l)):\n",
    "                sim[i, j, k] = (1 - np.abs(idealvec_s[k, i] ** p - datalearn_s[j, i]) ** p) ** (1 / p)\n",
    "\n",
    "    # Reduce the number of dimensions in sim\n",
    "    sim = sim.reshape((t, m * int(l))).T\n",
    "\n",
    "    # Possibility for two different entropy measures\n",
    "    if measure == 'luca':\n",
    "        # Modifying zero and one values of the similarity values to work with De Luca's entropy measure\n",
    "        delta = 1e-10\n",
    "        sim[sim == 0] = delta\n",
    "        sim[sim == 1] = 1 - delta\n",
    "        H = np.sum(-sim * np.log(sim) - (1 - sim) * np.log(1 - sim))\n",
    "    elif measure == 'park':\n",
    "        H = np.sum(np.sin(np.pi / 2 * sim) + np.sin(np.pi / 2 * (1 - sim)) - 1)\n",
    "\n",
    "    # Find the maximum feature\n",
    "    index_rem = np.argmax(H)\n",
    "\n",
    "    # Removing the feature from the data\n",
    "    data_mod = np.column_stack((dataold[:, :index_rem], dataold[:, index_rem + 1:]))\n",
    "\n",
    "    return data_mod, index_rem\n",
    "\n",
    "# Example usage with dummy data\n",
    "# Replace this with loading your MSL KDD dataset\n",
    "# data = np.loadtxt('path/to/your/msl_kdd_dataset.csv', delimiter=',')\n",
    "# data_mod, index_rem = feat_sel_sim(data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T22:41:50.562794Z",
     "start_time": "2024-02-04T22:41:50.527010Z"
    }
   },
   "id": "5637c1c6128e863",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/BinaryClassify/train_nsl_kdd_binary_encoded.csv\")\n",
    "df = pd.read_csv(\"../data/BinaryClassify/train_nsl_kdd_binary_encoded.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T00:09:28.689367Z",
     "start_time": "2024-02-05T00:09:28.425028Z"
    }
   },
   "id": "3524bb760eb6c8f6",
   "execution_count": 103
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data=data.values.astype(int)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T00:09:28.869566Z",
     "start_time": "2024-02-05T00:09:28.849642Z"
    }
   },
   "id": "5794ccfea0dbd2bd",
   "execution_count": 104
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f6/y0flg5mx57j3kyzn59jyn1sr0000gp/T/ipykernel_3968/737692697.py:23: RuntimeWarning: invalid value encountered in divide\n",
      "  data_v = data_v / maxs_v\n",
      "/var/folders/f6/y0flg5mx57j3kyzn59jyn1sr0000gp/T/ipykernel_3968/737692697.py:24: RuntimeWarning: invalid value encountered in divide\n",
      "  idealvec_s = idealvec_s / np.tile(maxs_v, (l, 1))\n"
     ]
    }
   ],
   "source": [
    "data_mod, index_rem = feat_sel_sim(data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T22:44:28.398344Z",
     "start_time": "2024-02-04T22:44:23.980452Z"
    }
   },
   "id": "85b6f6be198ce7a3",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_mod = data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T22:52:57.792201Z",
     "start_time": "2024-02-04T22:52:57.787988Z"
    }
   },
   "id": "d01d8776a8c55088",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f6/y0flg5mx57j3kyzn59jyn1sr0000gp/T/ipykernel_3968/737692697.py:23: RuntimeWarning: invalid value encountered in divide\n",
      "  data_v = data_v / maxs_v\n",
      "/var/folders/f6/y0flg5mx57j3kyzn59jyn1sr0000gp/T/ipykernel_3968/737692697.py:24: RuntimeWarning: invalid value encountered in divide\n",
      "  idealvec_s = idealvec_s / np.tile(maxs_v, (l, 1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125972, 42)\n",
      "0\n",
      "(125972, 41)\n",
      "0\n",
      "(125972, 40)\n",
      "0\n",
      "(125972, 39)\n",
      "0\n",
      "(125972, 38)\n",
      "0\n",
      "(125972, 37)\n",
      "0\n",
      "(125972, 36)\n",
      "0\n",
      "(125972, 35)\n",
      "0\n",
      "(125972, 34)\n",
      "0\n",
      "(125972, 33)\n",
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[28], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(data\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]):\n\u001B[0;32m----> 2\u001B[0m     data_mod, index_rem \u001B[38;5;241m=\u001B[39m \u001B[43mfeat_sel_sim\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_mod\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;28mprint\u001B[39m(data_mod\u001B[38;5;241m.\u001B[39mshape)\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;28mprint\u001B[39m(index_rem)\n",
      "Cell \u001B[0;32mIn[15], line 34\u001B[0m, in \u001B[0;36mfeat_sel_sim\u001B[0;34m(data, measure, p)\u001B[0m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(m):\n\u001B[1;32m     33\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(t):\n\u001B[0;32m---> 34\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43ml\u001B[49m\u001B[43m)\u001B[49m):\n\u001B[1;32m     35\u001B[0m             sim[i, j, k] \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m np\u001B[38;5;241m.\u001B[39mabs(idealvec_s[k, i] \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m p \u001B[38;5;241m-\u001B[39m datalearn_s[j, i]) \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m p) \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m/\u001B[39m p)\n\u001B[1;32m     37\u001B[0m \u001B[38;5;66;03m# Reduce the number of dimensions in sim\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(data.shape[1]):\n",
    "    data_mod, index_rem = feat_sel_sim(data_mod)\n",
    "    print(data_mod.shape)\n",
    "    print(index_rem)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T22:54:56.865281Z",
     "start_time": "2024-02-04T22:54:13.027053Z"
    }
   },
   "id": "96ee5c63ba323150",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(125972, 43)"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T22:53:25.632526Z",
     "start_time": "2024-02-04T22:53:25.629541Z"
    }
   },
   "id": "37c4832058755a3",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def feat_sel_sim(data, measure='luca', p=1):\n",
    "    # Check if p is provided, otherwise set default value\n",
    "    if p is None:\n",
    "        p = 1\n",
    "    \n",
    "    # Check if measure is provided, otherwise set default value\n",
    "    if measure is None:\n",
    "        measure = 'luca'\n",
    "\n",
    "    # Get the number of classes, samples, and features\n",
    "    l = np.max(data[:, -1])\n",
    "    m = data.shape[0]\n",
    "    t = data.shape[1] - 1\n",
    "\n",
    "    dataold = data.copy()\n",
    "\n",
    "    # Forming idealvec using arithmetic mean\n",
    "    idealvec_s = np.zeros((l, t))\n",
    "    for k in range(1, l+1):\n",
    "        idealvec_s[k-1, :] = np.mean(data[data[:, -1] == k, 0:t], axis=0)\n",
    "\n",
    "    # Scaling data between [0,1]\n",
    "    data_v = data[:, 0:t]\n",
    "    data_c = data[:, t]\n",
    "    mins_v = np.min(data_v, axis=0)\n",
    "    data_v = data_v + np.ones(data_v.shape) * np.abs(mins_v)\n",
    "\n",
    "    tmp = np.tile(np.abs(mins_v), (l, 1))\n",
    "    idealvec_s = idealvec_s + tmp\n",
    "\n",
    "    maxs_v = np.max(data_v, axis=0)\n",
    "    # Check if maxs_v contains zero values to avoid division by zero\n",
    "    maxs_v_nonzero = np.where(maxs_v == 0, 1, maxs_v)\n",
    "    data_v = data_v / maxs_v_nonzero  # Broadcasting corrected here\n",
    "\n",
    "    # Replace NaN or Inf values with zeros\n",
    "    data_v = np.nan_to_num(data_v)\n",
    "    idealvec_s = idealvec_s / np.tile(maxs_v_nonzero, (l, 1))\n",
    "    # Replace NaN or Inf values with zeros\n",
    "    idealvec_s = np.nan_to_num(idealvec_s)\n",
    "\n",
    "    data = np.column_stack((data_v, data_c))\n",
    "\n",
    "    # Sample data\n",
    "    datalearn_s = data[:, 0:t]\n",
    "\n",
    "    # Similarities\n",
    "    sim = np.zeros((t, m, l))\n",
    "    for j in range(m):\n",
    "        for i in range(t):\n",
    "            for k in range(l):\n",
    "                sim[i, j, k] = (1 - np.abs(idealvec_s[k, i]**p - datalearn_s[j, i])**p)**(1/p)\n",
    "\n",
    "    # Reduce number of dimensions in sim\n",
    "    sim = sim.reshape(t, m*l).T\n",
    "\n",
    "    # Possibility for two different entropy measures\n",
    "    if measure == 'luca':\n",
    "        # Modifying zero and one values of the similarity values to work with De Luca's entropy measure\n",
    "        delta = 1E-10\n",
    "        sim[sim == 0] = delta\n",
    "        sim[sim == 1] = 1 - delta\n",
    "        H = np.sum(-sim * np.log(sim) - (1 - sim) * np.log(1 - sim))\n",
    "\n",
    "    elif measure == 'park':\n",
    "        H = np.sum(np.sin(np.pi/2 * sim) + np.sin(np.pi/2 * (1 - sim)) - 1)\n",
    "\n",
    "    # Find maximum feature\n",
    "    index_rem = np.argmax(H)\n",
    "\n",
    "    # Removing feature from the data\n",
    "    data_mod = np.column_stack((dataold[:, 0:index_rem], dataold[:, index_rem+1:]))\n",
    "\n",
    "    return data_mod, index_rem\n",
    "\n",
    "# Example usage:\n",
    "# data = ...  # provide your data matrix\n",
    "# data_mod, index_rem = feat_sel_sim(data, measure='luca', p=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T00:22:24.512518Z",
     "start_time": "2024-02-05T00:22:24.505300Z"
    }
   },
   "id": "61cec816073894b1",
   "execution_count": 106
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1c784b98a14a1a0c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "measure='luca'\n",
    "p=1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T23:16:58.280703Z",
     "start_time": "2024-02-04T23:16:58.276709Z"
    }
   },
   "id": "b2389c1984f7eaf2",
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Check if p is provided, otherwise set default value\n",
    "if p is None:\n",
    "    p = 1\n",
    "    \n",
    "    # Check if measure is provided, otherwise set default value\n",
    "if measure is None:\n",
    "    measure = 'luca'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T23:18:11.442986Z",
     "start_time": "2024-02-04T23:18:11.437034Z"
    }
   },
   "id": "768c2c8d7c6315a0",
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "    # Get the number of classes, samples, and features\n",
    "l = np.max(data[:, -1])+1\n",
    "m = data.shape[0]\n",
    "t = data.shape[1] - 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T23:31:48.077269Z",
     "start_time": "2024-02-04T23:31:48.068669Z"
    }
   },
   "id": "1c519c812042bd10",
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dataold = data.copy()\n",
    "tmp = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T23:31:49.047770Z",
     "start_time": "2024-02-04T23:31:49.033703Z"
    }
   },
   "id": "3ef36940ca8b5409",
   "execution_count": 80
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aravind/Projects/IntrusionDetection/IntrusionDetection/venv/lib/python3.12/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/aravind/Projects/IntrusionDetection/IntrusionDetection/venv/lib/python3.12/site-packages/numpy/core/_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[82], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m idealvec_s \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros((l, t))\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;28mint\u001B[39m(l) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m----> 4\u001B[0m     \u001B[43midealvec_s\u001B[49m\u001B[43m[\u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmean(data[data[:, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m k, :t], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "\u001B[0;31mIndexError\u001B[0m: index 2 is out of bounds for axis 0 with size 2"
     ]
    }
   ],
   "source": [
    "# Forming idealvec using arithmetic mean\n",
    "idealvec_s = np.zeros((l, t))\n",
    "for k in range(0, int(l) + 1):\n",
    "    idealvec_s[k, :] = np.mean(data[data[:, -1] == k, :t], axis=0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T23:32:08.935336Z",
     "start_time": "2024-02-04T23:32:08.907015Z"
    }
   },
   "id": "ec74664123f8edf1",
   "execution_count": 82
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.68589899e+02, 1.16520151e+00, 2.70085682e+01, 8.60372427e+00,\n        1.31334671e+04, 4.32974952e+03, 1.03947017e-04, 0.00000000e+00,\n        1.48495738e-04, 2.30658430e-01, 1.38101037e-03, 7.10656054e-01,\n        5.07083247e-01, 2.03439161e-03, 2.04924119e-03, 5.62932494e-01,\n        2.22743607e-02, 6.08832527e-04, 7.49903478e-03, 0.00000000e+00,\n        1.48495738e-05, 1.29636779e-02, 2.25182501e+01, 2.76860355e+01,\n        5.98437825e-03, 4.88550979e-03, 4.13560631e-02, 4.07620801e-02,\n        9.41047192e-01, 1.46416798e-02, 6.81446942e-02, 1.47431885e+02,\n        1.90288215e+02, 6.25954085e-01, 7.72177838e-04, 3.75545722e-02,\n        1.72255056e-03, 9.65222298e-04, 4.90035936e-04, 2.99961391e-02,\n        1.86956134e-02, 2.03159247e+01]])"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idealvec_s"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T23:31:27.378627Z",
     "start_time": "2024-02-04T23:31:27.372447Z"
    }
   },
   "id": "1b7916e7b0b4e295",
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T23:29:09.900633Z",
     "start_time": "2024-02-04T23:29:09.890110Z"
    }
   },
   "id": "d4665c365c268bfd",
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def feat_sel_sim(data, measure='luca', p=1):\n",
    "    # Check if p is provided, otherwise set default value\n",
    "    if p is None:\n",
    "        p = 1\n",
    "    \n",
    "    # Check if measure is provided, otherwise set default value\n",
    "    if measure is None:\n",
    "        measure = 'luca'\n",
    "\n",
    "    l = int(np.max(data[:, -1])) + 1  # Increment by 1 for class label 0\n",
    "    m = data.shape[0]\n",
    "    t = data.shape[1] - 1\n",
    "\n",
    "    dataold = data.copy()\n",
    "    tmp = []\n",
    "\n",
    "    # Forming idealvec using arithmetic mean\n",
    "    idealvec_s = np.zeros((l, t))\n",
    "    for k in range(l):\n",
    "        idealvec_s[k, :] = np.mean(data[data[:, -1] == k, 0:t], axis=0)\n",
    "\n",
    "    # Scaling data between [0, 1]\n",
    "    data_v = data[:, 0:t]\n",
    "    data_c = data[:, t]\n",
    "    mins_v = np.min(data_v, axis=0)\n",
    "    data_v = data_v + np.ones(data_v.shape) * np.abs(mins_v)\n",
    "\n",
    "    tmp = np.tile(np.abs(mins_v), (l, 1))\n",
    "    idealvec_s = idealvec_s + tmp\n",
    "\n",
    "    maxs_v = np.max(data_v, axis=0)\n",
    "    maxs_v_nonzero = np.where(maxs_v == 0, 1, maxs_v)\n",
    "    data_v = data_v / maxs_v_nonzero\n",
    "\n",
    "    data_v = np.nan_to_num(data_v)\n",
    "    idealvec_s = idealvec_s / np.tile(maxs_v_nonzero, (l, 1))\n",
    "    idealvec_s = np.nan_to_num(idealvec_s)\n",
    "\n",
    "    data = np.column_stack((data_v, data_c))\n",
    "\n",
    "    # Sample data\n",
    "    datalearn_s = data[:, 0:t]\n",
    "\n",
    "    # Similarities\n",
    "    sim = np.zeros((t, m, l))\n",
    "    for j in range(m):\n",
    "        for i in range(t):\n",
    "            for k in range(l):\n",
    "                sim[i, j, k] = (1 - np.abs(idealvec_s[k, i]**p - datalearn_s[j, i])**p)**(1/p)\n",
    "\n",
    "    # Reduce number of dimensions in sim\n",
    "    sim = sim.reshape(t, m*l).T\n",
    "\n",
    "    # Possibility for two different entropy measures\n",
    "    if measure == 'luca':\n",
    "        delta = 1E-10\n",
    "        sim[sim == 0] = delta\n",
    "        sim[sim == 1] = 1 - delta\n",
    "        H = np.sum(-sim * np.log(sim) - (1 - sim) * np.log(1 - sim), axis=1)\n",
    "\n",
    "    elif measure == 'park':\n",
    "        H = np.sum(np.sin(np.pi/2 * sim) + np.sin(np.pi/2 * (1 - sim)) - 1, axis=1)\n",
    "\n",
    "    # Find maximum feature\n",
    "    index_rem = np.argmax(H)\n",
    "\n",
    "    # Removing feature from the data\n",
    "    data_mod = np.column_stack((dataold[:, 0:index_rem], dataold[:, index_rem+1:]))\n",
    "\n",
    "    return data_mod, index_rem\n",
    "\n",
    "# Example usage:\n",
    "# data = ...  # provide your data matrix with class labels 0 and 1\n",
    "# data_mod, index_rem = feat_sel_sim(data, measure='luca', p=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T23:36:10.089798Z",
     "start_time": "2024-02-04T23:36:10.082628Z"
    }
   },
   "id": "2fdd59356579d7af",
   "execution_count": 83
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_mod, index_rem = feat_sel_sim(data, measure='luca', p=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T23:36:32.934923Z",
     "start_time": "2024-02-04T23:36:24.152818Z"
    }
   },
   "id": "17eb0508be26981f",
   "execution_count": 84
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "808"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_rem"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-04T23:36:36.119205Z",
     "start_time": "2024-02-04T23:36:36.113716Z"
    }
   },
   "id": "bca23c3cf9354810",
   "execution_count": 85
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def feat_sel_sim(data, measure='luca', p=1):\n",
    "    \"\"\"\n",
    "    Feature selection using similarity measure and fuzzy entropy measures.\n",
    "\n",
    "    Args:\n",
    "        data (numpy.ndarray): Data matrix containing features and class values.\n",
    "        measure (str, optional): Fuzzy entropy measure to use.\n",
    "                                  Options are 'luca' or 'park'. Defaults to 'luca'.\n",
    "        p (float, optional): Parameter of Lukasiewicz similarity measure.\n",
    "                              Defaults to 1.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (data_mod, index_rem)\n",
    "            - data_mod (numpy.ndarray): Data without the removed feature.\n",
    "            - index_rem (int): Index of the removed feature in the original data.\n",
    "    \"\"\"\n",
    "\n",
    "    l = np.max(data[:, -1])  # Number of classes\n",
    "    m = data.shape[0]        # Number of samples\n",
    "    t = data.shape[1] - 1     # Number of features\n",
    "    dataold = data.copy()\n",
    "\n",
    "    # Form ideal vectors using arithmetic means for each class\n",
    "    idealvec = np.zeros((l, t))\n",
    "    for k in range(l):\n",
    "        idealvec[k, :] = np.mean(data[data[:, -1] == k, :-1], axis=0)\n",
    "\n",
    "    # Scale data between [0, 1]\n",
    "    data_v = data[:, :-1]\n",
    "    data_c = data[:, -1]  # Labels\n",
    "    mins_v = np.min(data_v, axis=0)\n",
    "    data_v = data_v + np.ones_like(data_v) * mins_v\n",
    "    maxs_v = np.max(data_v, axis=0)\n",
    "    maxs_v = np.max(data_v, axis=0)\n",
    "    for i in range(t):\n",
    "        if maxs_v[i] == 0:  # Check for zero\n",
    "            data_v[:, i] = 0  # Set entire column to zero\n",
    "            idealvec[:, i] = 0  # Set corresponding values in idealvec to zero\n",
    "        else:\n",
    "            data_v[:, i] /= maxs_v[i]\n",
    "            idealvec[:, i] /= maxs_v[i]\n",
    "    data_v = data_v / maxs_v\n",
    "    idealvec = idealvec / np.tile(maxs_v, (l, 1))\n",
    "    data = np.hstack((data_v, data_c[:, np.newaxis]))\n",
    "\n",
    "    # Calculate similarities\n",
    "    sim = np.zeros((t, m, l))\n",
    "    for j in range(m):\n",
    "        for i in range(t):\n",
    "            for k in range(l):\n",
    "                sim[i, j, k] = (1 - np.abs(idealvec[k, i]**p - data[j, i]**p)**p)**(1/p)\n",
    "\n",
    "    sim = sim.reshape(t, m * l).T\n",
    "\n",
    "    # Calculate fuzzy entropy\n",
    "    if measure == 'luca':\n",
    "        delta = 1e-10\n",
    "        sim[sim == 0] = delta\n",
    "        sim[sim == 1] = 1 - delta\n",
    "        H = -np.sum(sim * np.log(sim) + (1 - sim) * np.log(1 - sim), axis=1)\n",
    "    elif measure == 'park':\n",
    "        H = np.sum(np.sin(np.pi / 2 * sim) + np.sin(np.pi / 2 * (1 - sim)) - 1, axis=1)\n",
    "\n",
    "    # Find the feature with maximum entropy (corrected calculation)\n",
    "    index_rem = np.argmax(H)  # Directly find the index of the maximum element\n",
    "\n",
    "    # Remove the feature from the data (corrected indexing)\n",
    "    data_mod = np.hstack((dataold[:, :index_rem], dataold[:, index_rem + 1:]))\n",
    "\n",
    "    return data_mod, index_rem\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T00:08:23.268410Z",
     "start_time": "2024-02-05T00:08:23.265356Z"
    }
   },
   "id": "bae3ec6f498c8bdc",
   "execution_count": 101
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[105], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m data_mod, index_rem \u001B[38;5;241m=\u001B[39m \u001B[43mfeat_sel_sim\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmeasure\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mluca\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[101], line 26\u001B[0m, in \u001B[0;36mfeat_sel_sim\u001B[0;34m(data, measure, p)\u001B[0m\n\u001B[1;32m     23\u001B[0m dataold \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[1;32m     25\u001B[0m \u001B[38;5;66;03m# Form ideal vectors using arithmetic means for each class\u001B[39;00m\n\u001B[0;32m---> 26\u001B[0m idealvec \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mzeros\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43ml\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(l):\n\u001B[1;32m     28\u001B[0m     idealvec[k, :] \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmean(data[data[:, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m k, :\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "\u001B[0;31mTypeError\u001B[0m: 'numpy.float64' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "data_mod, index_rem = feat_sel_sim(data, measure='luca', p=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T00:09:34.805030Z",
     "start_time": "2024-02-05T00:09:34.776029Z"
    }
   },
   "id": "2a3c26f2c867eb28",
   "execution_count": 105
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_rem"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T00:05:14.581085Z",
     "start_time": "2024-02-05T00:05:14.576279Z"
    }
   },
   "id": "90b1d78cbf53d745",
   "execution_count": 95
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f6/y0flg5mx57j3kyzn59jyn1sr0000gp/T/ipykernel_3968/2068660233.py:36: RuntimeWarning: invalid value encountered in divide\n",
      "  data_v = data_v / maxs_v\n",
      "/var/folders/f6/y0flg5mx57j3kyzn59jyn1sr0000gp/T/ipykernel_3968/2068660233.py:37: RuntimeWarning: invalid value encountered in divide\n",
      "  idealvec = idealvec / np.tile(maxs_v, (l, 1))\n"
     ]
    }
   ],
   "source": [
    "data_mod, index_rem = feat_sel_sim(data_mod, measure='luca', p=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T00:05:28.712612Z",
     "start_time": "2024-02-05T00:05:23.916983Z"
    }
   },
   "id": "aff6340f3aab9bec",
   "execution_count": 96
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (50,) and (10,) not aligned: 50 (dim 0) != 10 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[113], line 52\u001B[0m\n\u001B[1;32m     49\u001B[0m data \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mrand(\u001B[38;5;241m10\u001B[39m, \u001B[38;5;241m50\u001B[39m)  \u001B[38;5;66;03m# Example data matrix\u001B[39;00m\n\u001B[1;32m     50\u001B[0m labels \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mrandint(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m50\u001B[39m)  \u001B[38;5;66;03m# Example class labels\u001B[39;00m\n\u001B[0;32m---> 52\u001B[0m selected_features \u001B[38;5;241m=\u001B[39m \u001B[43mfuzzy_entropy_feature_selection\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msimilarity_measure\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcosine\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSelected features:\u001B[39m\u001B[38;5;124m\"\u001B[39m, selected_features)\n",
      "Cell \u001B[0;32mIn[113], line 33\u001B[0m, in \u001B[0;36mfuzzy_entropy_feature_selection\u001B[0;34m(data, labels, similarity_measure)\u001B[0m\n\u001B[1;32m     31\u001B[0m     similarity \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m/\u001B[39m (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m+\u001B[39m np\u001B[38;5;241m.\u001B[39mlinalg\u001B[38;5;241m.\u001B[39mnorm(data[i, :] \u001B[38;5;241m-\u001B[39m ideal_vector))\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m similarity_measure \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcosine\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m---> 33\u001B[0m     similarity \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdot\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mideal_vector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mT\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m/\u001B[39m (np\u001B[38;5;241m.\u001B[39mlinalg\u001B[38;5;241m.\u001B[39mnorm(data[i, :]) \u001B[38;5;241m*\u001B[39m np\u001B[38;5;241m.\u001B[39mlinalg\u001B[38;5;241m.\u001B[39mnorm(ideal_vector))\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     37\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid similarity measure\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mValueError\u001B[0m: shapes (50,) and (10,) not aligned: 50 (dim 0) != 10 (dim 0)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def fuzzy_entropy_feature_selection(data, labels, similarity_measure='euclidean'):\n",
    "    \"\"\"\n",
    "    Performs feature selection using fuzzy entropy and similarity measures.\n",
    "\n",
    "    Args:\n",
    "        data: Data matrix (features as rows, samples as columns).\n",
    "        labels: Class labels for each sample.\n",
    "        similarity_measure: Similarity measure to use ('euclidean' or 'cosine').\n",
    "\n",
    "    Returns:\n",
    "        Indices of selected features with the lowest fuzzy entropy.\n",
    "    \"\"\"\n",
    "\n",
    "    classes = np.unique(labels)\n",
    "    num_features = data.shape[0]\n",
    "\n",
    "    # Calculate ideal vectors for each class\n",
    "    ideal_vectors = []\n",
    "    for c in classes:\n",
    "        class_data = data[:, labels == c]\n",
    "        ideal_vector = np.mean(class_data, axis=1)  # You can adjust this based on your needs\n",
    "        ideal_vectors.append(ideal_vector)\n",
    "\n",
    "    # Calculate similarity between each feature vector and the ideal vectors\n",
    "    similarity_matrix = np.zeros((num_features, len(classes)))\n",
    "    for i in range(num_features):  # Iterate over features (rows)\n",
    "        for j, ideal_vector in enumerate(ideal_vectors):\n",
    "            if similarity_measure == 'euclidean':\n",
    "                similarity = 1 / (1 + np.linalg.norm(data[i, :] - ideal_vector))\n",
    "            elif similarity_measure == 'cosine':\n",
    "                similarity = np.dot(data[i, :], ideal_vector.T) / (np.linalg.norm(data[i, :]) * np.linalg.norm(ideal_vector))\n",
    "\n",
    "\n",
    "            else:\n",
    "                raise ValueError(\"Invalid similarity measure\")\n",
    "            similarity_matrix[i, j] = similarity\n",
    "\n",
    "    # Calculate fuzzy entropy for each feature\n",
    "    fuzzy_entropy = -np.sum(similarity_matrix * np.log2(similarity_matrix), axis=1)\n",
    "\n",
    "    # Rank features by fuzzy entropy\n",
    "    feature_ranking = np.argsort(fuzzy_entropy)\n",
    "\n",
    "    return feature_ranking\n",
    "\n",
    "# Example usage:\n",
    "data = np.random.rand(10, 50)  # Example data matrix\n",
    "labels = np.random.randint(0, 2, 50)  # Example class labels\n",
    "\n",
    "selected_features = fuzzy_entropy_feature_selection(data, labels, similarity_measure='cosine')\n",
    "print(\"Selected features:\", selected_features)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T00:29:44.157892Z",
     "start_time": "2024-02-05T00:29:44.141098Z"
    }
   },
   "id": "d7e8ad03cf403356",
   "execution_count": 113
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 3 1 4 6 1]\n",
      " [9 2 1 7 4 1]\n",
      " [3 7 0 2 5 0]\n",
      " [4 1 1 5 1 1]\n",
      " [4 0 0 5 8 0]\n",
      " [0 9 0 6 3 0]\n",
      " [8 2 1 2 6 1]\n",
      " [4 8 1 1 3 1]\n",
      " [8 1 0 8 9 0]\n",
      " [4 1 0 6 7 0]\n",
      " [2 0 1 1 7 1]\n",
      " [3 1 1 5 9 1]\n",
      " [3 5 1 9 1 1]\n",
      " [9 3 0 6 8 0]\n",
      " [7 4 0 4 7 0]\n",
      " [9 8 0 0 8 0]\n",
      " [6 8 0 0 7 0]\n",
      " [7 2 0 7 2 0]\n",
      " [2 0 0 9 6 0]\n",
      " [9 8 1 8 7 1]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)  # Set seed for reproducibility\n",
    "\n",
    "num_samples = 20  # Number of samples\n",
    "num_features = 5  # Number of features\n",
    "num_classes = 2  # Number of classes\n",
    "\n",
    "# Generate random feature values\n",
    "data = np.random.randint(low=0, high=10, size=(num_samples, num_features))\n",
    "\n",
    "# Assign class labels randomly\n",
    "labels = np.random.randint(low=0, high=num_classes, size=num_samples)\n",
    "\n",
    "# Optional: Add some structure (e.g., make one feature perfectly correlated with labels)\n",
    "data[:, 2] = labels  # Set feature 2 to match class labels\n",
    "\n",
    "# Combine features and labels into a single NumPy array\n",
    "data = np.hstack((data, labels[:, np.newaxis]))\n",
    "\n",
    "# Print the generated array to verify its structure\n",
    "print(data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T00:34:13.009544Z",
     "start_time": "2024-02-05T00:34:12.997639Z"
    }
   },
   "id": "3e06c9de46b5e43c",
   "execution_count": 114
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def feat_sel_sim(data, measure='luca', p=1):\n",
    "    # Output initialization\n",
    "    data_mod = None\n",
    "    index_rem = None\n",
    "    \n",
    "    if p is None:\n",
    "        p = 1\n",
    "\n",
    "    if measure is None:\n",
    "        measure = 'luca'\n",
    "\n",
    "    l = np.max(data[:, -1])  # #-classes\n",
    "    m = data.shape[0]        # #-samples\n",
    "    t = data.shape[1] - 1    # #-features\n",
    "\n",
    "    dataold = np.copy(data)\n",
    "    tmp = []\n",
    "\n",
    "    # Forming idealvec using arithmetic mean\n",
    "    idealvec_s = np.zeros((l, t))\n",
    "    for k in range(1, l + 1):\n",
    "        idealvec_s[k-1, :] = np.mean(data[data[:, -1] == k, :t], axis=0)\n",
    "\n",
    "    # Scaling data between [0,1]\n",
    "    data_v = data[:, :t]\n",
    "    data_c = data[:, t]  # labels\n",
    "    mins_v = np.min(data_v, axis=0)\n",
    "    ones = np.ones(data_v.shape)\n",
    "    data_v = data_v + ones * np.abs(np.diag(mins_v))\n",
    "    tmp = np.tile(np.abs(mins_v), (l, 1))\n",
    "    idealvec_s = idealvec_s + tmp\n",
    "    maxs_v = np.max(data_v, axis=0)\n",
    "    data_v = data_v  / maxs_v\n",
    "    idealvec_s = idealvec_s / np.tile(maxs_v, (l, 1))\n",
    "    data = np.column_stack((data_v, data_c))\n",
    "\n",
    "    # Sample data\n",
    "    datalearn_s = data[:, :t]\n",
    "\n",
    "    # Similarities\n",
    "    sim = np.zeros((t, m, l))\n",
    "    for j in range(m):\n",
    "        for i in range(t):\n",
    "            for k in range(l):\n",
    "                sim[i, j, k] = (1 - np.abs(idealvec_s[k, i] ** p - datalearn_s[j, i]) ** p) ** (1 / p)\n",
    "\n",
    "    # Reduce the number of dimensions in sim\n",
    "    sim = np.reshape(sim, (t, m * l), order='F')\n",
    "\n",
    "    # Possibility for two different entropy measures\n",
    "    if measure == 'luca':\n",
    "        # Modifying zero and one values of the similarity values to work with De Luca's entropy measure\n",
    "        delta = 1E-10\n",
    "        sim[sim == 0] = delta\n",
    "        sim[sim == 1] = 1 - delta\n",
    "        H = np.sum(-sim * np.log(sim) - (1 - sim) * np.log(1 - sim))\n",
    "\n",
    "    elif measure == 'park':\n",
    "        H = np.sum(np.sin(np.pi / 2 * sim) + np.sin(np.pi / 2 * (1 - sim)) - 1)\n",
    "\n",
    "    # Find the maximum feature\n",
    "    index_rem = np.argmax(H)\n",
    "\n",
    "    # Removing feature from the data\n",
    "    data_mod = np.column_stack((dataold[:, :index_rem], dataold[:, index_rem + 1:]))\n",
    "    \n",
    "    return data_mod, index_rem\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T00:56:06.903390Z",
     "start_time": "2024-02-05T00:56:06.891754Z"
    }
   },
   "id": "cea044c88168534c",
   "execution_count": 125
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data[:,-1] = data[:,-1]+1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T00:53:20.276157Z",
     "start_time": "2024-02-05T00:53:20.269646Z"
    }
   },
   "id": "fd81a00d5f0f1c76",
   "execution_count": 120
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (20,5) (5,5) ",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[126], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m data_mod, index_rem \u001B[38;5;241m=\u001B[39m \u001B[43mfeat_sel_sim\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmeasure\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mluca\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[125], line 31\u001B[0m, in \u001B[0;36mfeat_sel_sim\u001B[0;34m(data, measure, p)\u001B[0m\n\u001B[1;32m     29\u001B[0m mins_v \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmin(data_v, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m     30\u001B[0m ones \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mones(data_v\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m---> 31\u001B[0m data_v \u001B[38;5;241m=\u001B[39m data_v \u001B[38;5;241m+\u001B[39m \u001B[43mones\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mabs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdiag\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmins_v\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     32\u001B[0m tmp \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mtile(np\u001B[38;5;241m.\u001B[39mabs(mins_v), (l, \u001B[38;5;241m1\u001B[39m))\n\u001B[1;32m     33\u001B[0m idealvec_s \u001B[38;5;241m=\u001B[39m idealvec_s \u001B[38;5;241m+\u001B[39m tmp\n",
      "\u001B[0;31mValueError\u001B[0m: operands could not be broadcast together with shapes (20,5) (5,5) "
     ]
    }
   ],
   "source": [
    "data_mod, index_rem = feat_sel_sim(data, measure='luca', p=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-05T00:56:09.755530Z",
     "start_time": "2024-02-05T00:56:09.741914Z"
    }
   },
   "id": "b253dade266a3ab4",
   "execution_count": 126
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9fc3d5074051ac25"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
